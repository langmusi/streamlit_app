{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Task_furniture v2.csv\", sep=\";\")\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.DwellingType.unique())\n",
    "print(df.Lifestage.unique)\n",
    "\n",
    "# checking where the missing values are\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers - detecting by z-score\n",
    "from scipy import stats\n",
    "\n",
    "print(df[(np.abs(stats.zscore(df[\"Age\"])) > 3)])\n",
    "df[(np.abs(stats.zscore(df[\"Salary\"])) > 3)]\n",
    "\n",
    "# dropping outliers\n",
    "df = df[(np.abs(stats.zscore(df[\"Age\"])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairwise variables visualization\n",
    "# Create the default pairplot\n",
    "sns.pairplot(df.drop(\"ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pair plot colored by continent with a density plot of the # diagonal and format the scatter plots.\n",
    "sns.pairplot(df.drop(columns = ['ID']), hue = 'City', diag_kind = 'kde',\n",
    "             plot_kws = {'alpha': 0.6, 's': 80, 'edgecolor': 'k'},\n",
    "             size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the categorical variables\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def pre_modeling(df, classification = True):\n",
    "    df_modelling = df.copy()\n",
    "    df_modelling['City'] = df_modelling['City'].astype(str)\n",
    "    \n",
    "    if classification == False:\n",
    "        df_modelling['Gender'] = df_modelling['Gender'].astype(str)\n",
    "        df_modelling['Gender'] = df_modelling['Gender'].replace(['0','1'],[\"Female\", \"Male\"])\n",
    "        # here is for Linear Regression\n",
    "        df_modelling = pd.get_dummies(df_modelling, columns = ['Gender', 'City', 'Lifestage', 'DwellingType'], drop_first=True)\n",
    "        df_modelling.drop(columns=['Target', 'ID'], inplace=True)\n",
    "        df_modelling.dropna(axis=0, subset=['Salary'], inplace=True)\n",
    "                \n",
    "    else:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_modelling.iloc[:, 3] = label_encoder.fit_transform(df_modelling.iloc[:, 3])\n",
    "        df_modelling.iloc[:, 4] = label_encoder.fit_transform(df_modelling.iloc[:, 4])\n",
    "        df_modelling.iloc[:, 5] = label_encoder.fit_transform(df_modelling.iloc[:, 5])\n",
    "        #df_modelling = pd.get_dummies(df_modelling, columns = ['Gender', 'City', 'Lifestage', 'DwellingType'], drop_first=False)\n",
    "        df_modelling.drop(columns=['Salary', 'ID'], inplace=True)\n",
    "    \n",
    "    return df_modelling\n",
    "\n",
    "# print(df_modelling.info())\n",
    "# df_modelling.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "df_modelling = pre_modeling(df, classification=False)    \n",
    "print(df_modelling.shape)\n",
    "print(df_modelling.head(2))\n",
    "\n",
    "y = df_modelling.pop('Salary')\n",
    "x = df_modelling\n",
    "\n",
    "X2 = sm.add_constant(x)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "\n",
    "# coeff_parameter = pd.DataFrame(model.coef_, x.columns, columns=['Coefficient'])\n",
    "# print(coeff_parameter)\n",
    "est2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train_salary, y_test_salary = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "feature_names = [f'feature {i}' for i in range(x.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=1234)\n",
    "forest.fit(X_train, y_train_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(forest, X_test, y_test_salary, n_repeats=10, random_state=1234, n_jobs=1)\n",
    "\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns[[0,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(forest, random_state=1234).fit(X_test, y_test_salary)\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Naive Bayes for Classification\n",
    "\n",
    "df_modelling = pre_modeling(df, classification=True)  \n",
    "\n",
    "y = df_modelling.pop('Target')\n",
    "x = df_modelling\n",
    "print(df_modelling.head(1))\n",
    "print(y[0:4])\n",
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "# summarize\n",
    "print('Train', x_train.shape, y_train.shape)\n",
    "print('Test', x_test.shape, y_test.shape)\n",
    "print(pd.value_counts(y_train))\n",
    "print(pd.value_counts(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixed_naive_bayes import MixedNB\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def naive_bayes_model(x, y, imblance_method):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "    nb_mod = MixedNB(categorical_features=[1,2,3,4])\n",
    "\n",
    "    if imblance_method == \"No\":\n",
    "        test_pred = nb_mod.fit(X_train, y_train).predict(X_test)\n",
    "        model_roc_auc_score = roc_auc_score(y_test, test_pred)\n",
    "        print('roc_auc_score=%.3f' % (model_roc_auc_score))\n",
    "        nb_precision, nb_recall, _ = precision_recall_curve(y_test, test_pred)\n",
    "        nb_f1, nb_auc = f1_score(y_test, test_pred), metrics.auc(nb_recall, nb_precision)\n",
    "        print('f1=%.3f precision/recall=%.3f' % (nb_f1, nb_auc))\n",
    "        \n",
    "    elif imblance_method == \"Undersampling\":\n",
    "        # summarize class distribution\n",
    "        print(\"Before undersampling: \", Counter(y_train))\n",
    "        # define undersampling strategy\n",
    "        undersample = RandomUnderSampler(sampling_strategy='majority', random_state = 1234)\n",
    "        # fit and apply the transform\n",
    "        X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "        # summarize class distribution\n",
    "        print(\"After undersampling: \", Counter(y_train_under))\n",
    "        test_pred = nb_mod.fit(X_train_under, y_train_under).predict(X_test)\n",
    "        model_roc_auc_score = roc_auc_score(y_test, test_pred)\n",
    "        print('roc_auc_score=%.3f' % (model_roc_auc_score))\n",
    "        nb_precision, nb_recall, _ = precision_recall_curve(y_test, test_pred)\n",
    "        nb_f1, nb_auc = f1_score(y_test, test_pred), metrics.auc(nb_recall, nb_precision)\n",
    "        print('f1=%.3f precision/recall=%.3f' % (nb_f1, nb_auc))\n",
    "     \n",
    "        \n",
    "    elif imblance_method == \"Oversampling\":\n",
    "        print(\"Before undersampling: \", Counter(y_train))\n",
    "        # define oversampling strategy\n",
    "        SMOTE_mod = SMOTE()\n",
    "        # fit and apply the transform\n",
    "        X_train_SMOTE, y_train_SMOTE = SMOTE_mod.fit_resample(X_train, y_train)\n",
    "        # summarize class distribution\n",
    "        print(\"After oversampling: \", Counter(y_train_SMOTE))\n",
    "        nb_mod = MixedNB(categorical_features=[1,2,3,4])\n",
    "        test_pred = nb_mod.fit(X_train_SMOTE, y_train_SMOTE).predict(X_test)\n",
    "        model_roc_auc_score = roc_auc_score(y_test, test_pred)\n",
    "        print('roc_auc_score=%.3f' % (model_roc_auc_score))\n",
    "        nb_precision, nb_recall, _ = precision_recall_curve(y_test, test_pred)\n",
    "        nb_f1, nb_auc = f1_score(y_test, test_pred), metrics.auc(nb_recall, nb_precision)\n",
    "        print('f1=%.3f precision/recall=%.3f' % (nb_f1, nb_auc))\n",
    "\n",
    "    return model_roc_auc_score, nb_f1, nb_auc          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model(x, y, imblance_method=\"Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model(x, y, imblance_method=\"Undersampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model(x, y, imblance_method=\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "nb_mod = MixedNB(categorical_features=[1,2,3,4])\n",
    "nb_mod.fit(x_train, y_train)\n",
    "perm = PermutationImportance(nb_mod, random_state=1234).fit(x_test, y_test)\n",
    "eli5.show_weights(perm, feature_names = x_test.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9c067bafa9a56659f08d4b27fad4d7f825c98eef37ebe6cb80b21191e0558b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('streamlit': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
